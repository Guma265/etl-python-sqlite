â€œEste repositorio muestra la evoluciÃ³n de un pipeline ETL en Python y SQLite, comenzando con una carga bÃ¡sica y evolucionando hacia un proceso batch con auditorÃ­a, idempotencia y modelo relacional.â€

# ETL Pipeline en Python con SQLite

Este repositorio muestra la evoluciÃ³n de un **pipeline ETL (Extract, Transform, Load)** desarrollado en Python, utilizando **SQLite** como base de datos local.  
El proyecto comienza con una carga bÃ¡sica y evoluciona hasta un **ETL batch con auditorÃ­a, idempotencia y modelo relacional**.

El objetivo es demostrar fundamentos sÃ³lidos de **data engineering a nivel junior**, con buenas prÃ¡cticas de estructura, validaciÃ³n y trazabilidad.

---

## Alcance del proyecto

El pipeline permite:

- Leer datos crudos desde archivos CSV
- Limpiar y normalizar informaciÃ³n
- Rechazar registros invÃ¡lidos con motivo
- Cargar datos en SQLite evitando duplicados
- Mantener auditorÃ­a de ejecuciones
- Procesar mÃºltiples archivos en modo batch

---

## Estructura del repositorio

etl-python-sqlite/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ etl_basic.py # ETL bÃ¡sico 
â”‚ â”œâ”€â”€ etl_refactor.py # RefactorizaciÃ³n a funciones 
â”‚ â”œâ”€â”€ etl_from_csv.py # ETL leyendo desde CSV 
â”‚ â”œâ”€â”€ etl_relational.py # Modelo relacional + rechazados 
â”‚ â”œâ”€â”€ etl_incremental_audit.py # ETL incremental con auditorÃ­a 
â”‚ â””â”€â”€ etl_batch.py # ETL batch (mÃºltiples CSV) 
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ in/ # Archivos CSV de entrada (ejemplo)
â”‚ â””â”€â”€ rejected/ # Registros rechazados (generados automÃ¡ticamente)
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸ”„ EvoluciÃ³n del pipeline

### â€” ETL bÃ¡sico
- Limpieza de datos
- Carga a SQLite
- PrevenciÃ³n de duplicados

###  â€” RefactorizaciÃ³n
- SeparaciÃ³n en funciones `extract`, `transform`, `load`
- CÃ³digo mÃ¡s mantenible

###  â€” Entrada desde CSV
- Lectura de datos externos
- Validaciones de formato

###  â€” Modelo relacional
- Tablas separadas (`personas`, `ciudades`)
- JOINs
- Manejo de registros rechazados (`rejected.csv`)

###  â€” Incremental + auditorÃ­a
- Carga incremental
- Campos `processed_at` y `run_id`
- Tabla `etl_runs` para trazabilidad

###  â€” ETL Batch
- Procesamiento de mÃºltiples CSV
- AuditorÃ­a por archivo
- `run_id` Ãºnico por ejecuciÃ³n
- Idempotencia total

---

##  Modelo de datos (SQLite)

### Tabla `personas_limpias`
- `persona_id`
- `nombre`
- `edad`
- `ciudad_id`
- `processed_at`
- `run_id`

### Tabla `ciudades`
- `ciudad_id`
- `nombre`

### Tabla `etl_runs`
- `run_id`
- `started_at`
- `source_file`
- `valid_count`
- `rejected_count`
- `inserted_new`
- `ignored_duplicates`

---

##  CÃ³mo ejecutar el ETL batch

1. Coloca uno o mÃ¡s archivos `.csv` en:

data/in/

2. Ejecuta:

```bash
python src/etl_batch.py
Resultados:
Datos vÃ¡lidos cargados en SQLite
Rechazados guardados en data/rejected/
AuditorÃ­a registrada en etl_runs

Buenas prÃ¡cticas implementadas
Idempotencia (el pipeline puede ejecutarse mÃºltiples veces sin duplicar datos)
ValidaciÃ³n y limpieza de datos
SeparaciÃ³n de responsabilidades
AuditorÃ­a de ejecuciones
Manejo explÃ­cito de errores

 TecnologÃ­as usadas
Python 3
SQLite
LibrerÃ­as estÃ¡ndar (csv, sqlite3, pathlib, datetime)

```

Notas
Este proyecto es educativo y demostrativo, enfocado en mostrar el proceso y la evoluciÃ³n de un ETL realista, no en manejar grandes volÃºmenes de datos.

Autor
Guillermo MR
Ingeniero FÃ­sico | Aprendiendo Data Engineering
